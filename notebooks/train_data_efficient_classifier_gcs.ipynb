{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5eciEDyU6BP"
      },
      "source": [
        "~~~\n",
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "~~~\n",
        "\n",
        "\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://colab.research.google.com/github/google-health/path-foundation/blob/master/notebooks/train_data_efficient_classifier_gcs.ipynb\"\u003e\n",
        "      \u003cimg alt=\"Google Colab logo\" src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" width=\"32px\"\u003e\u003cbr\u003e Run in Google Colab\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Fgoogle-health%2Fpath-foundation%2Fmaster%2Fnotebooks%2Ftrain_data_efficient_classifier_gcs.ipynb\"\u003e\n",
        "      \u003cimg alt=\"Google Cloud Colab Enterprise logo\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" width=\"32px\"\u003e\u003cbr\u003e Run in Colab Enterprise\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://github.com/google-health/path-foundation/blob/master/notebooks/train_data_efficient_classifier_gcs.ipynb\"\u003e\n",
        "      \u003cimg alt=\"GitHub logo\" src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" width=\"32px\"\u003e\u003cbr\u003e View on GitHub\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://huggingface.co/google/path-foundation\"\u003e\n",
        "      \u003cimg alt=\"HuggingFace logo\" src=\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\" width=\"32px\"\u003e\u003cbr\u003e View on HuggingFace\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n",
        "\n",
        "\n",
        "# Train a Digital Pathology Linear Classifier From Images Stored on Google Cloud Storage (GCS)\n",
        "\n",
        "This notebook is a demonstration of generating and using embeddings from the Path Foundation Serving API to train a linear classifier. This API enables users to compute embeddings for histopathology images. Note: This notebook is for API demonstration purposes only. As with all machine-learning use-cases it is critical to consider training and evaluation datasets that reflect the expected distribution of the intended use case.\n",
        "\n",
        "**Additional details**: For this demo, patches sampled from whole slide images (WSIs) are downloaded from Google Cloud Storage. A subset of the patches will be sampled randomly from across all available slides and embeddings will be generated via the Path Foundation model. The Colab supports two modes of execution, embeddings can be generated locally or in the Cloud using a Pathology Embeddings Research Endpoint.\n",
        "\n",
        "**Dataset**: This notebook uses the [CAMELYON16](https://camelyon16.grand-challenge.org/) dataset, which contains WSIs from lymph node specimens with and without metastatic breast cancer. Any work that uses this dataset should consider additional details along with usage and citation requirements listed on [their website](https://camelyon17.grand-challenge.org/Data/).\n",
        "\n",
        "**Dataset citation**: Babak Ehteshami Bejnordi; Mitko Veta; Paul Johannes van Diest; Bram van Ginneken; Nico Karssemeijer; Geert Litjens; Jeroen A. W. M. van der Laak; and the CAMELYON16 Consortium. Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer. JAMA. 2017;318(22):2199â€“2210. DOI: 10.1001/jama.2017.14585"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9E-VYsIGZLu"
      },
      "outputs": [],
      "source": [
        "# @title Pip install EZ-WSI DICOMweb\n",
        "%%capture\n",
        "!pip install --upgrade ez_wsi_dicomweb\u003e=6.0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MXA9uAPSZeT"
      },
      "source": [
        "### Define the endpoint to use to generate embeddings.\n",
        "\n",
        "This Colab supports generating embeddings locally or from a Vertex AI hosted pathology embeddings endpoint. The endpoint selector defines the endpoint which will be used.\n",
        "\n",
        "\n",
        "\n",
        "* **Generating Embeddings Locally** (Default): This option will generate embeddings using the pathology embeddings model hosted on [Hugging Face](https://huggingface.co/). Embeddings will be generated for the training and evaluation images hosted in GCS by downloading the images and running them across the model locally. The time required to complete this is typically 5 - 6 min but will be affected by the network bandwidth and computational resources of the local environment running the notebook. Retrieving the model from Hugging Face will require a valid Hugging Face account. Additional accounts are not required.\n",
        "* **Generate Embeddings In the Cloud**: This option will generate embeddings in the Cloud using a Pathology Embeddings Endpoint. The parameters that follow the end point selector default to settings that will utilize the Google Research Pathology Embeddings Endpoint. These parameters can be changed to point to private deployments. There is no charge associated with using the Google Research Embeddings endpoint. However, access to it is restricted to gain please see the [Research Endpoint Access](https://developers.google.com/health-ai-developer-foundations/model-serving/research-endpoints) page for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uwF4Wo58c9B"
      },
      "outputs": [],
      "source": [
        "Endpoint = 'Generate Embeddings In the Cloud'  # @param ['Generate Embeddings Locally', 'Generate Embeddings In the Cloud']\n",
        "\n",
        "Endpoint_Google_Cloud_Project = 'hai-cd3-foundations'  # @param {type: 'string'}\n",
        "Endpoint_Google_Cloud_Location = 'us-central1'  # @param {type: 'string'}\n",
        "Endpoint_ID = '162'  # @param {type: 'string'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaxxwnKG7opB"
      },
      "outputs": [],
      "source": [
        "# @title Retrieve list of images defined as representing cancer and benign imaging from Google Cloud Storage.\n",
        "import google.cloud.storage\n",
        "\n",
        "client = google.cloud.storage.Client.create_anonymous_client()\n",
        "bucket = google.cloud.storage.Bucket(name='healthai-us', client=client)\n",
        "\n",
        "# Patch imaging is statified by slide and stored within test and evaluation buckets\n",
        "# Retrieve a list of imaging stored in buckets, image bytes not retrieved here.\n",
        "cancer_imaging_training = list(\n",
        "    bucket.list_blobs(prefix='pathology/training/cancer')\n",
        ")\n",
        "benign_imaging_training = list(\n",
        "    bucket.list_blobs(prefix='pathology/training/benign')\n",
        ")\n",
        "cancer_imaging_eval = list(bucket.list_blobs(prefix='pathology/eval/cancer'))\n",
        "benign_imaging_eval = list(bucket.list_blobs(prefix='pathology/eval/benign'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US1lYjpwF6hh"
      },
      "outputs": [],
      "source": [
        "# @title Select a random subset of imaging for training and evaluation\n",
        "import random\n",
        "\n",
        "TRAINING_SIZE = 250\n",
        "EVAL_SIZE = 65\n",
        "\n",
        "# Randomize the image lists.\n",
        "random.shuffle(cancer_imaging_training)\n",
        "random.shuffle(benign_imaging_training)\n",
        "random.shuffle(cancer_imaging_eval)\n",
        "random.shuffle(benign_imaging_eval)\n",
        "\n",
        "# Take the 250 examples for training\n",
        "cancer_training = cancer_imaging_training[:TRAINING_SIZE]\n",
        "benign_training = benign_imaging_training[:TRAINING_SIZE]\n",
        "\n",
        "# Take the 65 examples for evaluation\n",
        "cancer_eval = cancer_imaging_eval[:EVAL_SIZE]\n",
        "benign_eval = benign_imaging_eval[:EVAL_SIZE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axippFnR8-iF"
      },
      "outputs": [],
      "source": [
        "# @title Authenticate notebook.\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "from huggingface_hub.utils import HfFolder\n",
        "from google.colab import auth\n",
        "\n",
        "if Endpoint == 'Generate Embeddings Locally':\n",
        "  if 'hugging_face_login' not in globals():\n",
        "    if HfFolder.get_token() is None:\n",
        "        notebook_login()\n",
        "    else:\n",
        "      print(\"Token already set\")\n",
        "    global hugging_face_login\n",
        "    hugging_face_login = True\n",
        "elif 'gcp_user_auth' not in globals():\n",
        "  # Authenticate user for access to Research Embedding Endpoint.\n",
        "  # There will be a popup asking you to sign in with your user account\n",
        "  # and approve access.\n",
        "  auth.authenticate_user()\n",
        "  global gcp_user_auth\n",
        "  gcp_user_auth = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBFMaZpyLHJB"
      },
      "outputs": [],
      "source": [
        "# @title Define Cloud or Local Endpoint used to Generate Embeddings.\n",
        "\n",
        "import functools\n",
        "\n",
        "from huggingface_hub import from_pretrained_keras\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def _load_huggingface_model() -\u003e tf.keras.Model:\n",
        "  \"\"\"Returns a model loaded from Hugging Face.\"\"\"\n",
        "\n",
        "  # Load model fom Hugging Face\n",
        "  if 'loaded_model' not in globals():\n",
        "    global loaded_model\n",
        "    loaded_model = from_pretrained_keras(\n",
        "        'google/path-foundation', compile=False\n",
        "    )\n",
        "  return loaded_model\n",
        "\n",
        "\n",
        "def _endpoint_model(ml_model: tf.keras.Model, image: np.ndarray) -\u003e np.ndarray:\n",
        "  \"\"\"Function ez-wsi will use to run local ML model.\"\"\"\n",
        "  result = ml_model.signatures['serving_default'](\n",
        "      tf.cast(tf.constant(image), tf.float32)\n",
        "  )\n",
        "  return result['output_0'].numpy()\n",
        "\n",
        "\n",
        "def create_embedding_endpoint_for_hugging_face_model() -\u003e (\n",
        "    patch_embedding_endpoints.LocalEndpoint\n",
        "):\n",
        "  \"\"\"Returns a endpoint that generates embeddings using model run locally.\"\"\"\n",
        "  # Use functools to define the value passed to the first parameter of the\n",
        "  # _endpoint model function\n",
        "  endpoint_model = functools.partial(_endpoint_model, _load_huggingface_model())\n",
        "  # Local endpoint takes a function which accepts a np.ndarray as a parameter\n",
        "  # and returns the generated embeddings as a np.ndarray.\n",
        "  # expected input shape [Batch, ImageDim, ImageDim, RGB_Channels]\n",
        "  return patch_embedding_endpoints.LocalEndpoint(endpoint_model)\n",
        "\n",
        "if Endpoint == 'Generate Embeddings Locally':\n",
        "  endpoint = create_embedding_endpoint_for_hugging_face_model()\n",
        "else:\n",
        "  endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint(\n",
        "      endpoint_api_version='v1',\n",
        "      project_id=Endpoint_Google_Cloud_Project,\n",
        "      endpoint_location=Endpoint_Google_Cloud_Location,\n",
        "      endpoint_id=Endpoint_ID,\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fut_v1DIFcTB"
      },
      "outputs": [],
      "source": [
        "# @title Generate embeddings for pathology Embedding Endpoint\n",
        "#\n",
        "# Patch embeddings are computed here. This cell will take ~5 min to execute.\n",
        "# Execution speed is dependent on local bandwith and compute. Imaging will be\n",
        "# downloaded from cloud and embeddings will be generated locally using the\n",
        "# model loaded from Hugging Face.\n",
        "\n",
        "import concurrent.futures\n",
        "from typing import List\n",
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding_types\n",
        "\n",
        "\n",
        "\n",
        "def generate_embeddings(patches) -\u003e List[patch_embedding_types.EmbeddingResult]:\n",
        "  \"\"\"Returns embeddings for list (patches) of images using the endpoint defined.\"\"\"\n",
        "  # Performance tip: Defining the image dimensions improves performance by\n",
        "  # enabling the client to know the dimensions of input imaging without having\n",
        "  # to retrieve the imaging. The patch imaging used in this Colab was saved as\n",
        "  # 224 x 224 pixels patches to match the endpoint input dimensions. If the\n",
        "  # defined image dimension does not match the actual image dimension the\n",
        "  # endpoint generating the image will resize the image to match the defined\n",
        "  # dimensions.\n",
        "  #\n",
        "  # For this colab embeddings are generated from the whole image.\n",
        "  embedding_result_iterator = patch_embedding.gcs_images_to_embeddings(\n",
        "          endpoint,\n",
        "          patches,\n",
        "          image_dimensions=gcs_image.ImageDimensions(224, 224),\n",
        "          credential_factory=credential_factory.NoAuthCredentialsFactory(),\n",
        "      )\n",
        "  return list(embedding_result_iterator)\n",
        "\n",
        "\n",
        "# Requeset embeddings in parallel for all four datasets.\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
        "  results = list(\n",
        "      executor.map(\n",
        "          generate_embeddings,\n",
        "          [cancer_training, benign_training, cancer_eval, benign_eval],\n",
        "      )\n",
        "  )\n",
        "training_cancer_embeddings = results[0]\n",
        "training_benign_embeddings = results[1]\n",
        "eval_cancer_embeddings = results[2]\n",
        "eval_benign_embeddings = results[3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ovli6nlc7c7R"
      },
      "outputs": [],
      "source": [
        "# @title Organize embeddings for ML training\n",
        "import os\n",
        "from typing import Sequence, Tuple\n",
        "\n",
        "\n",
        "def get_embeddings(\n",
        "    embedding_results: Sequence[patch_embedding_types.EmbeddingResult],\n",
        ") -\u003e np.ndarray:\n",
        "  \"\"\"Returns numpy array of embeddings returned in embedding results list.\"\"\"\n",
        "  return np.array([e.embedding for e in embedding_results])\n",
        "\n",
        "\n",
        "def get_slide_id(\n",
        "    embedding_results: Sequence[patch_embedding_types.EmbeddingResult],\n",
        ") -\u003e List[str]:\n",
        "  \"\"\"Returns list of patch slide ids encoded into patch GCS file name.\n",
        "\n",
        "  Patch file names were encoded with an id value that identifies the ID of the\n",
        "  the slide they came from, extract IDs from file names to use a clustering\n",
        "  index in StratifiedGroupKFold\n",
        "  \"\"\"\n",
        "  slide_id = []\n",
        "  # for each embedding result get the images GCS URI\n",
        "  for uri in [e.patch.source.uri for e in embedding_results]:\n",
        "    # split the file name into parts and extract the slide id\n",
        "    filename = uri.split('/')[-1]\n",
        "    slide_id.append(os.path.splitext(filename)[0].split('_')[-1])\n",
        "  return slide_id\n",
        "\n",
        "\n",
        "def concatenate_training_data_and_build_training_labels(\n",
        "    cancer: Sequence[patch_embedding_types.EmbeddingResult],\n",
        "    benign: Sequence[patch_embedding_types.EmbeddingResult],\n",
        ") -\u003e Tuple[np.ndarray, np.ndarray]:\n",
        "  \"\"\"Concatenate cancer and benign examples into and generate label data.\"\"\"\n",
        "  data = np.concatenate([get_embeddings(cancer), get_embeddings(benign)])\n",
        "  labels = np.concatenate((np.ones(len(cancer)), np.zeros(len(benign))))\n",
        "  return data, labels\n",
        "\n",
        "\n",
        "# Embeddings and training lables\n",
        "training_embeddings, training_labels = (\n",
        "    concatenate_training_data_and_build_training_labels(\n",
        "        training_cancer_embeddings, training_benign_embeddings\n",
        "    )\n",
        ")\n",
        "# Slide Ids for clustering.\n",
        "slide_ids = get_slide_id(training_cancer_embeddings)\n",
        "slide_ids.extend(get_slide_id(training_benign_embeddings))\n",
        "\n",
        "# Generate evaluation embeddings and labels\n",
        "eval_embeddings, eval_labels = (\n",
        "    concatenate_training_data_and_build_training_labels(\n",
        "        eval_cancer_embeddings, eval_benign_embeddings\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CIgAshDQE__"
      },
      "outputs": [],
      "source": [
        "# @title Train a linear classifier using the embeddings\n",
        "import warnings\n",
        "import sklearn.linear_model\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.pipeline\n",
        "import sklearn.preprocessing\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter('ignore')\n",
        "  clf_pipeline = sklearn.pipeline.Pipeline([\n",
        "      ('scaler', sklearn.preprocessing.StandardScaler()),\n",
        "      (\n",
        "          'logreg',\n",
        "          sklearn.model_selection.GridSearchCV(\n",
        "              sklearn.linear_model.LogisticRegression(\n",
        "                  random_state=0,\n",
        "                  multi_class='ovr',\n",
        "                  verbose=False,\n",
        "              ),\n",
        "              cv=sklearn.model_selection.StratifiedGroupKFold(n_splits=5).split(\n",
        "                  training_embeddings, y=training_labels, groups=slide_ids\n",
        "              ),\n",
        "              param_grid={'C': np.logspace(start=-4, stop=4, num=10, base=10)},\n",
        "              scoring='roc_auc_ovr',\n",
        "              refit=True,\n",
        "          ),\n",
        "      ),\n",
        "  ]).fit(training_embeddings, training_labels)\n",
        "\n",
        "  test_predictions = clf_pipeline.predict_proba(eval_embeddings)[:, 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEiAoRwV7V_v"
      },
      "outputs": [],
      "source": [
        "# @title Evaluate the linear classifiers performance using the eval patches\n",
        "sklearn.metrics.roc_auc_score(eval_labels, test_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxgKZgWqjAOM"
      },
      "outputs": [],
      "source": [
        "# @title Plot the ROC Curve\n",
        "\n",
        "display = sklearn.metrics.RocCurveDisplay.from_predictions(\n",
        "    eval_labels, test_predictions, name=\"Tumor Classifier\"\n",
        ")\n",
        "display.ax_.set_title(\"ROC of Tumor Classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjc23U507MUc"
      },
      "outputs": [],
      "source": [
        "# @title Find Youden's index for threshold selection\n",
        "\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "for threshold in thresholds:\n",
        "  predictions = test_predictions \u003e threshold\n",
        "  sensitivities.append(sklearn.metrics.recall_score(eval_labels, predictions))\n",
        "  specificities.append(\n",
        "      sklearn.metrics.recall_score(eval_labels == 0, predictions == 0)\n",
        "  )\n",
        "index = np.argmax(np.array(sensitivities) + np.array(specificities))\n",
        "best_threshold = thresholds[index]\n",
        "sens = sensitivities[index]\n",
        "spec = specificities[index]\n",
        "print(\n",
        "    f\"Best threshold: {round(best_threshold,2)}. Sensitivity is\"\n",
        "    f\" {round(sens*100,2)}% and Specificity is {round(spec*100,2)}% \"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17s-mvrW7IT7"
      },
      "outputs": [],
      "source": [
        "# @title Show the results in a table\n",
        "import pandas as pd\n",
        "\n",
        "eval_embeddings_obj = eval_cancer_embeddings + eval_benign_embeddings\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    {'ground_truth': eval_labels, 'model_score': test_predictions}\n",
        ")\n",
        "df['tumor_prediction'] = df['model_score'] \u003e best_threshold\n",
        "df['embeddings'] = [e.embedding for e in eval_embeddings_obj]\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es9ZvZYe6utq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def render_patch_from_embedding(\n",
        "    patch: gcs_image.GcsPatch, plot_name: str = ''\n",
        ") -\u003e None:\n",
        "  patch_bytes = patch.image_bytes()\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.imshow(patch_bytes)\n",
        "  plt.title(plot_name)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# @title Visualize True Positives\n",
        "def display_results(\n",
        "    tumor_prediction: bool, ground_truth: int, title: str\n",
        ") -\u003e None:\n",
        "  df_tp = (\n",
        "      df[\n",
        "          (df['tumor_prediction'] == tumor_prediction)\n",
        "          \u0026 (df['ground_truth'] == ground_truth)\n",
        "      ]\n",
        "      .sort_values('model_score', ascending=False)\n",
        "      .head(5)\n",
        "  )\n",
        "  for index, row in df_tp.iterrows():\n",
        "    print(index)\n",
        "    print(f'model score is {row.model_score}')\n",
        "    render_patch_from_embedding(eval_embeddings_obj[index].patch, title)\n",
        "\n",
        "\n",
        "display_results(True, 1, 'True Positive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3uaFT3b68WQ"
      },
      "outputs": [],
      "source": [
        "# @title Visualize True Negatives\n",
        "display_results(False, 0, 'True Negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR6J7KN77CE7"
      },
      "outputs": [],
      "source": [
        "# @title Visualize False Positives\n",
        "display_results(True, 0, 'False Positive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vON3jeOj7ELU"
      },
      "outputs": [],
      "source": [
        "# @title Visualize False Negatives\n",
        "display_results(False, 1, 'False Negative')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWEcfgttY0zU"
      },
      "source": [
        "# Next steps\n",
        "\n",
        " Explore the other [notebooks](https://github.com/google-health/path-foundation/blob/master/notebooks)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
