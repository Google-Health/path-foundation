{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "u_OIwDav0A4W"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_oWMJLg0fLk"
      },
      "source": [
        "# Quick start with Model Garden - Path Foundation\n",
        "\n",
        "<table><tbody><tr>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Fgoogle-health%2Fpath-foundation%2Fmaster%2Fnotebooks%2Fquick_start_with_model_garden.ipynb\">\n",
        "      <img alt=\"Google Cloud Colab Enterprise logo\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" width=\"32px\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/google-health/path-foundation/blob/master/notebooks/quick_start_with_model_garden.ipynb\">\n",
        "      <img alt=\"GitHub logo\" src=\"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\" width=\"32px\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</tr></tbody></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsEU-DK7DJcv"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates deploying Path Foundation to Vertex AI and making online predictions to get embeddings from pathology image patches.\n",
        "\n",
        "Vertex AI makes it easy to serve your model and make it accessible to the world. Learn more about [Vertex AI](https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform).\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Deploy Path Foundation to a Vertex AI Endpoint and get online predictions.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe_iHV1RDA3C"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CNFc5UrVsnSx"
      },
      "outputs": [],
      "source": [
        "# @title Import packages and define common functions\n",
        "\n",
        "! pip install --upgrade --quiet 'ez-wsi-dicomweb>=6.0.5'\n",
        "\n",
        "import importlib\n",
        "import os\n",
        "from typing import Iterator, Union\n",
        "\n",
        "import ez_wsi_dicomweb.ml_toolkit.dicom_path as dicom_path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ez_wsi_dicomweb import (credential_factory, dicom_slide,\n",
        "                             dicom_web_interface, gcs_image, local_image,\n",
        "                             patch_embedding, patch_embedding_endpoints,\n",
        "                             patch_embedding_ensemble_methods)\n",
        "\n",
        "if not os.path.isdir(\"vertex-ai-samples\"):\n",
        "    ! git clone https://github.com/GoogleCloudPlatform/vertex-ai-samples.git\n",
        "\n",
        "common_util = importlib.import_module(\n",
        "    \"vertex-ai-samples.community-content.vertex_model_garden.model_oss.notebook_util.common_util\"\n",
        ")\n",
        "\n",
        "models, endpoints = {}, {}\n",
        "\n",
        "\n",
        "def render_patch(\n",
        "    patch: Union[dicom_slide.DicomPatch, gcs_image.GcsPatch], plot_name: str = \"\"\n",
        ") -> None:\n",
        "    \"\"\"Displays a patch from a DICOM slide or Cloud Storage image.\"\"\"\n",
        "    patch_bytes = patch.image_bytes()\n",
        "    # Transforms monochrome imaging to three RGB channel representation.\n",
        "    if len(patch_bytes.shape) == 2 or (\n",
        "        len(patch_bytes.shape) == 3 and patch_bytes.shape[-1] == 1\n",
        "    ):\n",
        "        mem = np.zeros((224, 224, 3), dtype=patch_bytes.dtype)\n",
        "        mem[..., np.arange(3)] = patch_bytes[...]\n",
        "        patch_bytes = mem\n",
        "    print(patch_bytes.shape)\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    plt.imshow(patch_bytes)\n",
        "    plt.title(plot_name)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2_aYhzoEDMCf"
      },
      "outputs": [],
      "source": [
        "# @title Set up Google Cloud environment\n",
        "\n",
        "# @markdown #### Prerequisites\n",
        "\n",
        "# @markdown 1. Make sure that [billing is enabled](https://cloud.google.com/billing/docs/how-to/modify-project) for your project.\n",
        "\n",
        "# @markdown 2. Make sure that either the Compute Engine API is enabled or that you have the [Service Usage Admin](https://cloud.google.com/iam/docs/understanding-roles#serviceusage.serviceUsageAdmin) (`roles/serviceusage.serviceUsageAdmin`) role to enable the API.\n",
        "\n",
        "# @markdown This section sets the default Google Cloud project and region and enables the Compute Engine API (if not already enabled).\n",
        "\n",
        "# Get the default project ID.\n",
        "PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "\n",
        "# Get the default region for launching jobs.\n",
        "REGION = os.environ[\"GOOGLE_CLOUD_REGION\"]\n",
        "\n",
        "# Enable the Compute Engine API, if not already.\n",
        "print(\"Enabling Compute Engine API.\")\n",
        "! gcloud services enable compute.googleapis.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esqJ6FxovLSm"
      },
      "source": [
        "## Use of EZ-WSI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz55I2smvFiH"
      },
      "source": [
        "This notebook leverages [EZ-WSI DICOMweb](https://github.com/GoogleCloudPlatform/EZ-WSI-DICOMweb), which makes it easier to work with DICOM data and generate embeddings from a variety of data sources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYDtoLtUTukW"
      },
      "source": [
        "## Get online predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sH_nJGKNFdlw"
      },
      "outputs": [],
      "source": [
        "# @title Import deployed model\n",
        "\n",
        "# @markdown To get [online predictions](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions), you will need a Path Foundation [Vertex AI Endpoint](https://cloud.google.com/vertex-ai/docs/general/deployment) that has been deployed from Model Garden. If you have not already done so, go to the [Path Foundation model card](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/path-foundation) in Model Garden and click \"Deploy\" to deploy the model.\n",
        "\n",
        "# @markdown This section instantiates a [V2PatchEmbeddingEndpoint class](https://github.com/GoogleCloudPlatform/EZ-WSI-DICOMweb/blob/0927ad2dcc73e5315f6af2bd4d022c3fe925e8bf/ez_wsi_dicomweb/patch_embedding_endpoints.py#L1369), which is an implementation of an abstraction interface through which EZ-WSI requests and receives embeddings. It defines a connection to the Path Foundation Vertex AI Endpoint and will be called to generate embeddings in the next sections.\n",
        "\n",
        "# @markdown Fill in the endpoint ID and region below. You can find your deployed endpoint on the [Vertex AI online prediction page](https://console.cloud.google.com/vertex-ai/online-prediction/endpoints).\n",
        "\n",
        "ENDPOINT_ID = \"\"  # @param {type: \"string\", placeholder:\"e.g. 123456789\"}\n",
        "ENDPOINT_REGION = \"\"  # @param {type: \"string\", placeholder:\"e.g. us-central1\"}\n",
        "\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint(\n",
        "    project_id=PROJECT_ID,\n",
        "    endpoint_location=ENDPOINT_REGION,\n",
        "    endpoint_id=ENDPOINT_ID,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-DQ60z-oyqR"
      },
      "source": [
        "### Predict\n",
        "\n",
        "You can send [online prediction requests](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions#predict-request) to the endpoint with image patches, cropped sub-regions of a digital pathology image, to generate embeddings.\n",
        "\n",
        "The following examples demonstrate using Path Foundation and leveraging EZ-WSI to generate embeddings for a single patch, multiple patches, or a whole image from:\n",
        "\n",
        "* A DICOM image stored in [Cloud Healthcare DICOM Store](https://cloud.google.com/healthcare-api/docs/how-tos/dicom)\n",
        "* An image stored in [Cloud Storage](https://cloud.google.com/storage/docs)\n",
        "* A local in-memory representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysm7hqCzBwzE"
      },
      "source": [
        "#### Generate a single patch embedding\n",
        "\n",
        "These examples demonstrate the simplest patch-to-embedding interface using EZ-WSI to generate an embedding for a single patch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "trU5YDBEHwn-"
      },
      "outputs": [],
      "source": [
        "# @title ##### From a DICOM image\n",
        "\n",
        "# @markdown This section shows an example of generating a single patch embedding from a DICOM image stored in a Google-hosted DICOM store containing the [Camelyon16 dataset](https://camelyon16.grand-challenge.org/).\n",
        "# @markdown To access this dataset, request access to our [research endpoint](https://developers.google.com/health-ai-developer-foundations/model-serving/research-endpoints).\n",
        "\n",
        "# @markdown You can replace the fields below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Defines DICOM image stored in a DICOM store\n",
        "DATASET_PROJECT_ID = \"hai-cd3-foundations\"  # @param {type:\"string\", placeholder:\"Project ID\"}\n",
        "DATASET_LOCATION = \"us-west1\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset location\"}\n",
        "DATASET_ID = \"pathology\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset ID\"}\n",
        "STORE_ID = \"camelyon\"  # @param {type:\"string\", placeholder:\"DICOM store ID\"}\n",
        "STUDY_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461\"  # @param {type:\"string\", placeholder:\"DICOM study instance UID\"}\n",
        "SERIES_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463\"  # @param {type:\"string\", placeholder:\"DICOM series instance UID\"}\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging\n",
        "series_path = dicom_path.FromString(\n",
        "    f\"https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}\"\n",
        ")\n",
        "\n",
        "# Credential factory that provides EZ-WSI with credentials to access DICOM imaging metadata\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide; retrieves slide metadata but not slide imaging\n",
        "ds = dicom_slide.DicomSlide(\n",
        "    path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf)\n",
        ")\n",
        "\n",
        "# Request a single patch of imaging from the highest magnfication\n",
        "patch = ds.get_patch(level=ds.native_level, x=43000, y=10000, width=224, height=224)\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (optional, for illustrating the source imaging for the embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in the embedding\n",
        "print(embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "u0g2Ei_D99kT"
      },
      "outputs": [],
      "source": [
        "# @title ##### From an image in Cloud Storage\n",
        "\n",
        "# @markdown This section shows an example of generating a single patch embedding from an image stored in Cloud Storage.\n",
        "\n",
        "# @markdown You can replace `GCS_URI` below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "GCS_URI = \"gs://healthai-us/pathology/example_large_patch.jpeg\"  # @param {type:\"string\", placeholder:\"Cloud Storage file URI\"}\n",
        "\n",
        "# Create a reference to an image stored in Cloud Storage.\n",
        "# Authenticates with default credentials by default.\n",
        "image = gcs_image.GcsImage(\n",
        "    GCS_URI, credential_factory=credential_factory.NoAuthCredentialsFactory()\n",
        ")\n",
        "\n",
        "# Define coordinates of image patch\n",
        "patch = image.get_patch(x=10, y=10, width=224, height=224)\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (optional, for illustrating the source imaging for the embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in the embedding\n",
        "print(embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nqBgXxjM-WUt"
      },
      "outputs": [],
      "source": [
        "# @title ##### From local in-memory data\n",
        "\n",
        "# @markdown This section shows an example of generating a single patch embedding from an in-memory NumPy array.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Create an in-memory uncompressed image\n",
        "memory = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "\n",
        "# Construct an image from the in-memory patch\n",
        "image = local_image.LocalImage(memory)\n",
        "\n",
        "# Define coordinates of image patch\n",
        "patch = image.get_patch(x=0, y=0, width=224, height=224)\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (optional, for illustrating the source imaging for the embedding)\n",
        "render_patch(patch, \"Image is expected to be entirely black\")\n",
        "\n",
        "# Display first 12 values in the embedding\n",
        "print(embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmNjHufDB9mw"
      },
      "source": [
        "#### Generate multiple patch embeddings\n",
        "\n",
        "EZ-WSI provides general-purpose interfaces that greatly reduce the time required to generate embeddings for multiple patches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZmdFgDkX2fM9"
      },
      "outputs": [],
      "source": [
        "# @title ##### From a DICOM image\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings for multiple patches from a DICOM image stored in a Google-hosted DICOM store containing the [Camelyon16 dataset](https://camelyon16.grand-challenge.org/).\n",
        "# @markdown To access this dataset, request access to our [research endpoint](https://developers.google.com/health-ai-developer-foundations/model-serving/research-endpoints).\n",
        "\n",
        "# @markdown You can replace the fields below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Defines DICOM image stored in a DICOM store\n",
        "DATASET_PROJECT_ID = \"hai-cd3-foundations\"  # @param {type:\"string\", placeholder:\"Project ID\"}\n",
        "DATASET_LOCATION = \"us-west1\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset location\"}\n",
        "DATASET_ID = \"pathology\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset ID\"}\n",
        "STORE_ID = \"camelyon\"  # @param {type:\"string\", placeholder:\"DICOM store ID\"}\n",
        "STUDY_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461\"  # @param {type:\"string\", placeholder:\"DICOM study instance UID\"}\n",
        "SERIES_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463\"  # @param {type:\"string\", placeholder:\"DICOM series instance UID\"}\n",
        "\n",
        "\n",
        "def patch_generator(\n",
        "    ds: dicom_slide.DicomSlide,\n",
        "    level: dicom_slide.Level,\n",
        "    x: int,\n",
        "    y: int,\n",
        "    step: int,\n",
        "    num_patches: int,\n",
        ") -> Iterator[dicom_slide.DicomPatch]:\n",
        "    \"\"\"Generates sequential patches at a pyramid level of a DICOM slide.\"\"\"\n",
        "    for _ in range(num_patches):\n",
        "        yield ds.get_patch(level, x, y, 224, 224)\n",
        "        x += step\n",
        "        if x + step >= level.width:\n",
        "            x = 0\n",
        "            y += step\n",
        "\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging\n",
        "series_path = dicom_path.FromString(\n",
        "    f\"https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}\"\n",
        ")\n",
        "\n",
        "# Credential factory that provides EZ-WSI with credentials to access DICOM imaging metadata\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide; retrieves slide metadata but not slide imaging\n",
        "ds = dicom_slide.DicomSlide(\n",
        "    path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf)\n",
        ")\n",
        "\n",
        "# Generate 500 patches sampled across a single pyramid.\n",
        "# Note: the generator can return patches sampled across multiple pyramid\n",
        "# layers or images. The only requirement is that patches from the same source\n",
        "# image or pyramid layer are clustered.\n",
        "patches = patch_generator(ds, ds.native_level, 43000, 10000, 224, 500)\n",
        "\n",
        "# Takes the patches (DicomPatch or GcsPatch) and returns embeddings\n",
        "embeddings = patch_embedding.generate_patch_embeddings(endpoint, patches)\n",
        "\n",
        "# Convert the embedding generator into a list of values\n",
        "embeddings = list(embeddings)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print(\"First two embeddings results\")\n",
        "for result in embeddings[:2]:\n",
        "    # Render the source embedding patch\n",
        "    render_patch(result.patch)\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F38EH3o25ZY4"
      },
      "outputs": [],
      "source": [
        "# @title ##### From an image in Cloud Storage\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings for multiple patches from an image stored in Cloud Storage.\n",
        "\n",
        "# @markdown You can replace `GCS_URI` below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "GCS_URI = \"gs://healthai-us/pathology/example_large_patch.jpeg\"  # @param {type:\"string\", placeholder:\"Cloud Storage file URI\"}\n",
        "\n",
        "\n",
        "def patch_generator(\n",
        "    image: gcs_image.GcsImage, x: int, y: int, step: int, num_patches: int\n",
        ") -> Iterator[gcs_image.GcsPatch]:\n",
        "    \"\"\"Generates sequential patches at a pyramid level of a DICOM slide.\"\"\"\n",
        "    for _ in range(num_patches):\n",
        "        yield image.get_patch(x, y, 224, 224)\n",
        "        x += step\n",
        "        if x + 224 >= image.width:\n",
        "            x = 0\n",
        "            y += step\n",
        "\n",
        "\n",
        "# Create a reference to an image stored in Cloud Storage.\n",
        "# Authenticates with default credentials by default.\n",
        "image = gcs_image.GcsImage(\n",
        "    GCS_URI, credential_factory=credential_factory.NoAuthCredentialsFactory()\n",
        ")\n",
        "\n",
        "# Generate 500 patches sampled across the Cloud Storage image.\n",
        "# Since the image is relatively small, generate overlapping embeddings\n",
        "# by stepping the patches 10 pixels at a time.\n",
        "patches = patch_generator(image, 0, 0, 10, 500)\n",
        "\n",
        "# Takes the patches (DicomPatch or GcsPatch) and returns embeddings\n",
        "embeddings = patch_embedding.generate_patch_embeddings(endpoint, patches)\n",
        "\n",
        "# Convert the embedding generator into a list of values\n",
        "embeddings = list(embeddings)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for two embeddings returned\n",
        "print(\"Embeddings results\")\n",
        "for result in (embeddings[0], embeddings[20]):\n",
        "    # Render the source embedding patch\n",
        "    render_patch(result.patch)\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jIxyZ4TC5duc"
      },
      "outputs": [],
      "source": [
        "# @title ##### From local in-memory data\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings for multiple patches from an in-memory NumPy array.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "\n",
        "def patch_generator(\n",
        "    image: local_image.LocalImage, x: int, y: int, step: int, num_patches: int\n",
        ") -> Iterator[gcs_image.GcsPatch]:\n",
        "    \"\"\"Generates sequential patches at a pyramid level of a DICOM slide.\"\"\"\n",
        "    for _ in range(num_patches):\n",
        "        yield image.get_patch(x, y, 224, 224)\n",
        "        x += step\n",
        "        if x + 224 >= image.width:\n",
        "            x = 0\n",
        "            y += step\n",
        "\n",
        "\n",
        "# Create an in-memory uncompressed image filled with random noise\n",
        "memory = np.random.randint(0, high=255, size=(224 * 50, 224, 3), dtype=np.uint8)\n",
        "\n",
        "# Construct an image from the in-memory patch\n",
        "image = local_image.LocalImage(memory)\n",
        "\n",
        "# Generates 50 patches sampled across the image.\n",
        "# Since the image is relatively small, generate overlapping embeddings\n",
        "# by stepping the patches 10 pixels at a time.\n",
        "patches = patch_generator(image, 0, 0, 224, 50)\n",
        "\n",
        "# Takes the patches (DicomPatch or GcsPatch) and returns embeddings\n",
        "embeddings = patch_embedding.generate_patch_embeddings(endpoint, patches)\n",
        "\n",
        "# Convert the embedding generator into a list of values\n",
        "embeddings = list(embeddings)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for two embeddings returned\n",
        "print(\"Embeddings results\")\n",
        "for result in (embeddings[0], embeddings[20]):\n",
        "    # Render the source embedding patch\n",
        "    render_patch(result.patch, \"Random Colors Expected\")\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3kJlefQCGpj"
      },
      "source": [
        "#### Generate whole image embeddings\n",
        "\n",
        "EZ-WSI contains high-level patch generation functions to selectively generate patches from regions of interest (e.g. areas containing tissue) within a whole image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5eKAiXP-_eZ5"
      },
      "outputs": [],
      "source": [
        "# @title ##### From a DICOM image\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings that are selectively sampled across a DICOM image stored in a Google-hosted DICOM store containing the [Camelyon16 dataset](https://camelyon16.grand-challenge.org/).\n",
        "# @markdown To access this dataset, request access to our [research endpoint](https://developers.google.com/health-ai-developer-foundations/model-serving/research-endpoints).\n",
        "\n",
        "# @markdown You can replace the fields below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Defines DICOM image stored in a DICOM store\n",
        "DATASET_PROJECT_ID = \"hai-cd3-foundations\"  # @param {type:\"string\", placeholder:\"Project ID\"}\n",
        "DATASET_LOCATION = \"us-west1\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset location\"}\n",
        "DATASET_ID = \"pathology\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset ID\"}\n",
        "STORE_ID = \"camelyon\"  # @param {type:\"string\", placeholder:\"DICOM store ID\"}\n",
        "STUDY_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461\"  # @param {type:\"string\", placeholder:\"DICOM study instance UID\"}\n",
        "SERIES_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463\"  # @param {type:\"string\", placeholder:\"DICOM series instance UID\"}\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging\n",
        "series_path = dicom_path.FromString(\n",
        "    f\"https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}\"\n",
        ")\n",
        "\n",
        "# Credential factory that provides EZ-WSI with credentials to access DICOM imaging metadata\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide; retrieves slide metadata but not slide imaging\n",
        "ds = dicom_slide.DicomSlide(\n",
        "    path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf)\n",
        ")\n",
        "\n",
        "# Optional but highly recommended; enables DS to retrieve patch imaging more\n",
        "# efficiently when generating the tissue mask\n",
        "ds.init_slide_frame_cache()\n",
        "\n",
        "embeddings = patch_embedding.get_dicom_image_embeddings(endpoint, ds, ds.native_level)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print(\"First two embeddings results\")\n",
        "for result in embeddings[:2]:\n",
        "    # Render the source embedding patch\n",
        "    render_patch(result.patch)\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Oheuw8WnDNWd"
      },
      "outputs": [],
      "source": [
        "# @title ##### From an image in Cloud Storage\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings that are selectively sampled from an image stored in Cloud Storage.\n",
        "\n",
        "# @markdown You can replace `GCS_URI` below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "GCS_URI = \"gs://healthai-us/pathology/example_large_patch.jpeg\"  # @param {type:\"string\", placeholder:\"Cloud Storage file URI\"}\n",
        "\n",
        "# Create a reference to an image stored in Cloud Storage.\n",
        "# Authenticates with default credentials by default.\n",
        "image = gcs_image.GcsImage(\n",
        "    GCS_URI, credential_factory=credential_factory.NoAuthCredentialsFactory()\n",
        ")\n",
        "\n",
        "embeddings = patch_embedding.get_gcs_image_embeddings(endpoint, image)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print(\"First two embeddings results\")\n",
        "for result in embeddings[:2]:\n",
        "    # Render the source embedding patch\n",
        "    render_patch(result.patch)\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EF9U0osEDaY_"
      },
      "outputs": [],
      "source": [
        "# @title ##### From local in-memory data\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings that are selectively sampled from an in-memory NumPy array.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Create an in-memory uncompressed image filled with random noise.\n",
        "memory = np.random.randint(0, high=255, size=(224 * 50, 224, 3), dtype=np.uint8)\n",
        "\n",
        "# Construct an image from the in-memory patch\n",
        "image = local_image.LocalImage(memory)\n",
        "\n",
        "embeddings = patch_embedding.get_gcs_image_embeddings(endpoint, image)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print(\"First two embeddings results\")\n",
        "for result in embeddings[:2]:\n",
        "    # Render the source embedding patch\n",
        "    render_patch(result.patch)\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "APdqxI66FYJj"
      },
      "outputs": [],
      "source": [
        "# @title ##### Reduce embedding results to a single embedding\n",
        "\n",
        "# @markdown The selectively-generated embeddings for a whole image can be reduced into a single embedding using a utility function.\n",
        "\n",
        "# @markdown This section shows an example of returning the mean embedding result of all the embeddings in the results sequence.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "image = gcs_image.GcsImage(\n",
        "    \"gs://healthai-us/pathology/example_large_patch.jpeg\",\n",
        "    credential_factory=credential_factory.NoAuthCredentialsFactory(),\n",
        ")\n",
        "embeddings = patch_embedding.get_gcs_image_embeddings(endpoint, image)\n",
        "\n",
        "print(f\"Reducing {len(embeddings)} to a single embedding.\")\n",
        "# Reduces the 20 embeddings returned by `get_gcs_image_embeddings` to a single\n",
        "# embedding\n",
        "embedding = patch_embedding_ensemble_methods.mean_patch_embedding(embeddings)\n",
        "\n",
        "print(\"First 12 values of patch image embedding.\")\n",
        "print(embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAfNL0Y0nP2_"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Explore the other [notebooks](https://github.com/google-health/path-foundation/blob/master/notebooks) to learn what else you can do with the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQMUmDYr6O_O"
      },
      "source": [
        "## Clean up resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iOSY_r6mHYui"
      },
      "outputs": [],
      "source": [
        "# @markdown  Delete the experiment models and endpoints to recycle the resources\n",
        "# @markdown  and avoid unnecessary continuous charges that may incur.\n",
        "\n",
        "# Undeploy model and delete endpoint.\n",
        "for endpoint in endpoints.values():\n",
        "    endpoint.delete(force=True)\n",
        "\n",
        "# Delete models.\n",
        "for model in models.values():\n",
        "    model.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "quick_start_with_model_garden.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
